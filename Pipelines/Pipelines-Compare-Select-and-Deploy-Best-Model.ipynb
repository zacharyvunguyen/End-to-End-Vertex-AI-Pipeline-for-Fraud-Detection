{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b59f1fb-5557-4f89-9ee6-505e1ccc8509",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "The pipeline is structured into key phases to streamline the model lifecycle management:\n",
    "\n",
    "### 1. Candidate Selection\n",
    "- **Registry Query:** Fetch models tagged with the `series` label and the `default` version alias from the Vertex AI Model Registry.\n",
    "- **Performance Evaluation:** Execute parallel assessments of candidates focusing on key metrics like accuracy, ROC curves, and confusion matrices.\n",
    "- **Model Selection:** Identify the model that exhibits superior performance across the evaluation criteria.\n",
    "\n",
    "### 2. Deployment and Monitoring\n",
    "- **Endpoint Management:** Evaluate the existing deployment state; if no model is actively deployed, initialize a new endpoint.\n",
    "- **Model Comparison:** For an active deployment, compare the newly selected model against the current one in terms of traffic and performance metrics.\n",
    "- **Model Update:** Should the new model outperform the existing deployment, proceed to update the endpoint with the selected model, ensuring optimal performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de3982-2555-4d5c-bae6-8e7d35710557",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870ab11-b5dc-4378-830c-b39feaaa5384",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "GOOGLE_APPLICATION_CREDENTIALS = \"/Users/zacharynguyen/Documents/GitHub/2024/End-to-End-Vertex-AI-Pipeline-for-Fraud-Detection/key/e2e-fraud-detection-debf1c9863af.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.176216Z",
     "start_time": "2024-03-19T16:38:29.057511Z"
    }
   },
   "id": "e65b4c02b0a6c210",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb73f2d6-e658-445c-8a2a-3c65edfe423a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.213722Z",
     "start_time": "2024-03-19T16:38:29.189813Z"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'e2e-fraud-detection'\n",
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'pipeline-bqml-best-model'\n",
    "SERIES = 'bqml'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud_dataset'\n",
    "BQ_TABLE = 'prepped-data'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1e984-dcde-4348-a72a-6848ac2a7538",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "968c1a4a-512f-4553-8e8c-130df1100a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.285211Z",
     "start_time": "2024-03-19T16:38:29.224491Z"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "\n",
    "from typing import NamedTuple\n",
    "from google_cloud_pipeline_components import v1\n",
    "from kfp import dsl\n",
    "from kfp.dsl import importer_node\n",
    "from kfp import compiler\n",
    "from kfp.dsl import Artifact, Input, Metrics, ClassificationMetrics, HTML, Output, component\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f8e48-531b-45b3-ad29-b64557cab774",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbd2df68-d747-45e7-9448-ec9454508407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.382976Z",
     "start_time": "2024-03-19T16:38:29.297927Z"
    }
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01eff3-dd34-4842-b477-bd9d72314a8c",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a4ca5abe-d716-4376-b7e7-9a8b6f8d45e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.384716Z",
     "start_time": "2024-03-19T16:38:29.339499Z"
    }
   },
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}/pipelines\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "94bd031b-f214-418b-b5b9-4e6497621956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.454642Z",
     "start_time": "2024-03-19T16:38:29.352975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'zacharynguyen@e2e-fraud-detection.iam.gserviceaccount.com'"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = 'zacharynguyen@e2e-fraud-detection.iam.gserviceaccount.com'\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fed662-28ee-4348-aad1-b4aecd942a21",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "366d859b-84bd-412c-8b52-22a8aca7af55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.480685Z",
     "start_time": "2024-03-19T16:38:29.391111Z"
    }
   },
   "outputs": [],
   "source": [
    "#!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#!gcloud projects get-iam-policy fraud-mlops --format=json | grep -B 1 -A 2 \"zacharynguyen@fraud-mlops.iam.gserviceaccount.com\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.561709Z",
     "start_time": "2024-03-19T16:38:29.467781Z"
    }
   },
   "id": "cfe91664c2556829",
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "id": "29145297-e1c9-4667-97e7-5213cc3850de",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1d92b-35ec-4925-8aa2-e63a0dd84267",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91e41643-6611-41dc-9519-ac0b129457d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.944349Z",
     "start_time": "2024-03-19T16:38:29.531764Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc790f5f-1805-4d09-90c9-a05f632f8571",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a43fa-c7a1-4336-91d1-d6d17a523513",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "This section follows the process I take to build a workflow as a Vertex AI Pipeline.  \n",
    "1. Create an outline of the workflow\n",
    "2. Prepare components, custom or prebuilt for each step\n",
    "3. Define the pipeline\n",
    "4. Compile and run the pipeline\n",
    "\n",
    "The build process can be iterative where 2, 3, and 4 and created and tested as iterative steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d632c-8f90-455e-a207-d46ad0100eb4",
   "metadata": {},
   "source": [
    "### 1 - Outline Pipeline\n",
    "\n",
    "Write down in words the flow you want to achieve along with any conditional elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979a503-704f-4fd7-8aa8-cb95796d8807",
   "metadata": {},
   "source": [
    "- Candidate selection path:\n",
    "    - Get list of candidate models: Vertex AI Model Registry where labels.series={SERIES} and version_alias=default\n",
    "    - Loop (async) over list of candidate models\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Pick the best candidate model\n",
    "- Current model review path:\n",
    "    - Check for endpoint, create if needed\n",
    "    - Get the deployed model with most traffic \n",
    "    - Condition: if there is a deployed model\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Condition: if there is not a deployed model\n",
    "        - deploy best on endpoint\n",
    "- Compare And update Path:\n",
    "    - Condition: if best > deployed\n",
    "        - deploy best on endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a9a23-2cab-45bc-b60f-8699a0ee0d5f",
   "metadata": {},
   "source": [
    "### 2 - Prepare Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ee8ed-a458-4f7d-9be5-d56a4c46d9bc",
   "metadata": {},
   "source": [
    "#### Component: list_series_models\n",
    "Get a list of BQML model names that are registred in the Vertex AI Model Registry for the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "694cc82a-ff9b-44a9-90d6-d9388117a858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:29.962761Z",
     "start_time": "2024-03-19T16:38:29.921591Z"
    }
   },
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\"]\n",
    ")\n",
    "def list_series_models(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str\n",
    ") -> NamedTuple('outputs', [('candidates', list)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['candidates'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # get list of candidate models for series\n",
    "    #candidates = [f\"{model.name}\" for model in aiplatform.Model.list(filter = f\"labels.series={series}\")]\n",
    "    candidates = [f\"{model.labels['series']}_{model.labels['experiment']}_{model.labels['timestamp']}\" for model in aiplatform.Model.list(filter = f\"labels.series={series}\")]\n",
    "\n",
    "    return result(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78b2d5-891c-4e3d-aab6-12381b95159f",
   "metadata": {},
   "source": [
    "#### Component: bqml_evaluate\n",
    "Gather evaluation metrics for a specified BQML model: metrics, confusion matric, ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "be4b0fd4-bd61-47da-b4b4-4c01f8200b35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:30.029165Z",
     "start_time": "2024-03-19T16:38:29.937307Z"
    }
   },
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['pandas', 'db-dtypes', 'google-cloud-bigquery', 'google-cloud-storage']\n",
    ")\n",
    "def bqml_evaluate(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_model: str,\n",
    "    bq_test_table: str,\n",
    "    bq_results: str,\n",
    "    best_metric: str,\n",
    "    metrics: Output[Metrics],\n",
    "    class_metrics: Output[ClassificationMetrics]\n",
    ") -> NamedTuple('outputs', [('best_metric', float)]):\n",
    "\n",
    "    # setup\n",
    "    import json\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = bq_project)\n",
    "    from google.cloud import storage\n",
    "    gcs = storage.Client(project = project)\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['best_metric'])\n",
    "    \n",
    "    # BQML: ML.EVALUTE\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM ML.EVALUATE (\n",
    "        MODEL `{bq_project}.{bq_dataset}.{bq_model}`,\n",
    "        (SELECT * FROM `{bq_test_table}`)\n",
    "    )\n",
    "    \"\"\"\n",
    "    bq_eval = bq.query(query = query).to_dataframe()\n",
    "    bq_eval = bq_eval.to_dict(orient = 'records')[0]\n",
    "    for key in bq_eval:\n",
    "        metrics.log_metric(key, bq_eval[key])\n",
    "\n",
    "    # BQML: ML.CONFUSION_MATRIX\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM ML.CONFUSION_MATRIX (\n",
    "        MODEL `{bq_project}.{bq_dataset}.{bq_model}`,\n",
    "        (SELECT * FROM `{bq_test_table}`)\n",
    "    )\n",
    "    \"\"\"\n",
    "    bq_cm = bq.query(query = query).to_dataframe()\n",
    "    classes = ['Not Fraud', 'Fraud']\n",
    "    # ignore the 'trial_id' column that is included when hyperparameter tuning is used and skip the first=label column\n",
    "    matrix = bq_cm.loc[:, bq_cm.columns != 'trial_id'].iloc[:, 1:].values.tolist()\n",
    "    class_metrics.log_confusion_matrix(classes, matrix)\n",
    "\n",
    "    # BQML: ML.ROC_CURVE\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM ML.ROC_CURVE (\n",
    "        MODEL `{bq_project}.{bq_dataset}.{bq_model}`,\n",
    "        (SELECT * FROM `{bq_test_table}`)\n",
    "    )\n",
    "    \"\"\"\n",
    "    bq_roc = bq.query(query = query).to_dataframe()\n",
    "    class_metrics.log_roc_curve(\n",
    "        bq_roc['false_positive_rate'].tolist(),\n",
    "        bq_roc['recall'].tolist(),\n",
    "        bq_roc['threshold'].tolist()\n",
    "    )\n",
    "    \n",
    "    # save bq_eval results to common file {'candidate': bq_eval}\n",
    "    file = f\"bq_eval_{bq_model}.json\"\n",
    "    bq_eval['candidate'] = bq_model\n",
    "    with open(file, 'w') as fp:\n",
    "        json.dump(bq_eval, fp)\n",
    "    \n",
    "    bucket = gcs.bucket(project)\n",
    "    path = bq_results.split(f'gs://{project}/')[-1]\n",
    "    blob = bucket.blob(f\"{path}/{file}\")\n",
    "    blob.upload_from_filename(f\"{file}\")\n",
    "    \n",
    "    return result(bq_eval[best_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd098e-8045-4c9c-8577-e7855cbce6e4",
   "metadata": {},
   "source": [
    "#### Component: best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "from typing import NamedTuple\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=['pandas', 'google-cloud-storage', 'pretty_html_table']\n",
    ")\n",
    "def best_candidate(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    bq_results: str,\n",
    "    best_metric: str,\n",
    "    candidates: list,\n",
    "    metrics: Output[Artifact]  # Adjusted from HTML to Artifact for generalization\n",
    ") -> NamedTuple('outputs', [('best_candidate', str), ('best_metric', float)]):\n",
    "\n",
    "    # setup\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from pretty_html_table import build_table\n",
    "    from google.cloud import storage\n",
    "    from collections import namedtuple\n",
    "    import os\n",
    "\n",
    "    gcs = storage.Client(project=project)\n",
    "    Result = namedtuple('outputs', ['best_candidate', 'best_metric'])\n",
    "\n",
    "    # retrieve bq_results to a list of dictionaries: bq_evals = [{}, {}, ...]\n",
    "    path = bq_results.split(f'gs://{project}/')[-1]\n",
    "    bucket = gcs.bucket(project)\n",
    "    blobs = list(bucket.list_blobs(prefix=path))\n",
    "\n",
    "    if not blobs:\n",
    "        raise ValueError(f\"No files found in {bq_results}. Ensure the path is correct and files exist.\")\n",
    "\n",
    "    candidate_evals = []\n",
    "    for blob in blobs:\n",
    "        _, filename = os.path.split(blob.name)\n",
    "        blob.download_to_filename(filename)\n",
    "        with open(filename, 'r') as fp:\n",
    "            evals = json.load(fp)\n",
    "        # Ensure the file contains 'candidate' key and it's in the list of candidates\n",
    "        if 'candidate' in evals and evals['candidate'] in candidates:\n",
    "            candidate_evals.append(evals)\n",
    "\n",
    "    if not candidate_evals:\n",
    "        raise ValueError(\"No evaluation data found for the specified candidates.\")\n",
    "\n",
    "    # convert list of dictionaries to pandas dataframe:\n",
    "    df_candidates = pd.DataFrame(candidate_evals)\n",
    "\n",
    "    # Ensure best_metric column exists in the dataframe\n",
    "    if best_metric not in df_candidates.columns:\n",
    "        raise ValueError(f\"The best_metric '{best_metric}' is not available in the evaluation data.\")\n",
    "\n",
    "    # pick best candidate based on best_metric:\n",
    "    ascending = best_metric in ['log_loss']\n",
    "    df_candidates['best'] = df_candidates[best_metric].rank(method='dense', ascending=ascending)\n",
    "    best_row = df_candidates.loc[df_candidates['best'] == 1].iloc[0]\n",
    "\n",
    "    # output evals to HTML Table in metrics:\n",
    "    with open(metrics.path, 'w') as fp:\n",
    "        fp.write(build_table(df_candidates.drop(columns=['best']), 'blue_light'))\n",
    "\n",
    "    return Result(best_row['candidate'], best_row[best_metric])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:30.078973Z",
     "start_time": "2024-03-19T16:38:29.961985Z"
    }
   },
   "id": "e519ea934f005ecd",
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "7978a6bb-ee9a-498e-9ec9-41716204b636",
   "metadata": {},
   "source": [
    "#### Component: get_endpoint\n",
    "\n",
    "Look for Vertex AI Endpoint for the series and if missing, create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e86fac55-f382-4de4-aebd-76ad06ae64e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:30.080956Z",
     "start_time": "2024-03-19T16:38:29.987788Z"
    }
   },
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def get_endpoint(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    bq_dataset: str \n",
    ") -> NamedTuple('outputs', [('endpoint_resource_name', str)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['endpoint_resource_name'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # retrieve endpoint\n",
    "    endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={series}\")\n",
    "    if endpoints:\n",
    "        endpoint = endpoints[0]\n",
    "        print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "    else:\n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "            display_name = f\"{series}\",\n",
    "            labels = {'series' : f\"{series}\"}    \n",
    "        )\n",
    "        print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "    return result(endpoint.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf104d1-ff70-4bfb-9a09-a0593a8f24a6",
   "metadata": {},
   "source": [
    "#### Component: get_deployed_model\n",
    "\n",
    "Get the models deployed on the endpoint and return one with most/all traffic:"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def get_deployed_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    endpoint_resource_name: str,\n",
    ") -> NamedTuple('outputs', [('model', str)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['model'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # retrieve endpoint\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name = endpoint_resource_name)\n",
    "    \n",
    "    # retrieve deployed model with most traffic and get BQML model name\n",
    "    traffic_split = endpoint.traffic_split\n",
    "    if traffic_split:\n",
    "        deployed_model_id = max(traffic_split, key = traffic_split.get)\n",
    "        if deployed_model_id:\n",
    "            for model in endpoint.list_models():\n",
    "                if model.id == deployed_model_id:\n",
    "                    deployed_model = model.model+f'@{model.model_version_id}'\n",
    "            deployed_model = aiplatform.Model(model_name = deployed_model)\n",
    "            bq_model = deployed_model.display_name+f\"_{deployed_model.labels['timestamp']}\"\n",
    "        else: bq_model = 'none'\n",
    "    else: bq_model = 'none'\n",
    "    \n",
    "    return result(bq_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:30.142590Z",
     "start_time": "2024-03-19T16:38:30.014174Z"
    }
   },
   "id": "20650a1c2e285abf",
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "id": "1ff0b771-1b67-4eca-939e-44e5c6279086",
   "metadata": {},
   "source": [
    "#### Component: deploy_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "89eda5c6-51ab-4457-85ec-d41e79fc2b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:30.162087Z",
     "start_time": "2024-03-19T16:38:30.036479Z"
    }
   },
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def deploy_candidate(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    endpoint_resource_name: str,\n",
    "    bq_model: str\n",
    ") -> NamedTuple('outputs', [('model_version', str)]):\n",
    "\n",
    "    DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "    \n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['model_version'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # retrieve endpoint\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name = endpoint_resource_name)\n",
    "    \n",
    "    # retrieve model\n",
    "    model_display_name = ('_').join(bq_model.split('_')[0:-1])\n",
    "    model_timestamp = bq_model.split('_')[-1]\n",
    "    model_experiment = bq_model.split('_')[1]\n",
    "    model = aiplatform.Model.list(filter = f\"labels.series={series} AND labels.experiment={model_experiment}\")[0]\n",
    "    \n",
    "    # get all versions of the model:\n",
    "    client_options = {\"api_endpoint\": f\"{region}-aiplatform.googleapis.com\"}\n",
    "    model_client = aiplatform.gapic.ModelServiceClient(client_options = client_options)\n",
    "    model_versions = list(model_client.list_model_versions(name = model.resource_name))\n",
    "    for version in model_versions:\n",
    "        if version.labels['timestamp'] == model_timestamp:\n",
    "           model = aiplatform.Model(model_name = version.name) \n",
    "    \n",
    "    # deploy the candidate model to the endpoint with 100% traffic\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "    \n",
    "    # remove models without traffic\n",
    "    for deployed_model in endpoint.list_models():\n",
    "        if deployed_model.id in endpoint.traffic_split:\n",
    "            print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "        else:\n",
    "            endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "            print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")\n",
    "\n",
    "    return result(model.versioned_resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be29e5-cf54-4ec4-b230-05ea70bb3759",
   "metadata": {},
   "source": [
    "### 3 - Define Pipeline\n",
    "\n",
    "Recall the Outline, notice it is include as comments in the pipeline definition below:\n",
    "- Candidate selection path:\n",
    "    - Get list of candidate models: Vertex AI Model Registry where labels.series={SERIES} and version_alias=default\n",
    "    - Loop (async) over list of candidate models\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Pick the best candidate model\n",
    "- Current model review path:\n",
    "    - Check for endpoint, create if needed\n",
    "    - Get the deployed model with most traffic \n",
    "    - Condition: if there is a deployed model\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Condition: if there is not a deployed model\n",
    "        - deploy best on endpoint\n",
    "- Compare And update Path:\n",
    "    - Condition: if best > deployed\n",
    "        - deploy best on endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "94adf436-290e-4b63-b21d-5738df88fe38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:30.207325Z",
     "start_time": "2024-03-19T16:38:30.043347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/ckh165qn5c9dfv779dwrmdh80000gn/T/ipykernel_27816/3474820946.py:73: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(\n",
      "/var/folders/lh/ckh165qn5c9dfv779dwrmdh80000gn/T/ipykernel_27816/3474820946.py:93: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(\n",
      "/var/folders/lh/ckh165qn5c9dfv779dwrmdh80000gn/T/ipykernel_27816/3474820946.py:108: DeprecationWarning: dsl.Condition is deprecated. Please use dsl.If instead.\n",
      "  with dsl.Condition(\n"
     ]
    }
   ],
   "source": [
    "# from kfp import dsl\n",
    "@dsl.pipeline(\n",
    "    name = f'series-{SERIES}-endpoint-update',\n",
    "    description = 'Update endpoint with best model.'\n",
    ")\n",
    "def endpoint_update_pipeline(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_test_table: str,\n",
    "    bq_results: str,\n",
    "    best_metric: str\n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from kfp.dsl import importer_node\n",
    "    \n",
    "# - Candidate selection path:\n",
    "    \n",
    "    candidate_models = list_series_models(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series\n",
    "    ).set_display_name('List Models in Series').set_caching_options(True)\n",
    "    \n",
    "    # - Loop (async) over list of candidate models\n",
    "    with dsl.ParallelFor(candidate_models.outputs['candidates']) as candidate:\n",
    "        \n",
    "        # - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "        candidate_metrics = bqml_evaluate(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            bq_project = bq_project,\n",
    "            bq_dataset = bq_dataset,\n",
    "            bq_model = candidate,\n",
    "            bq_test_table = bq_test_table,\n",
    "            bq_results = bq_results,\n",
    "            best_metric = best_metric\n",
    "        ).set_display_name('Gather Candidate Metrics').set_caching_options(True)\n",
    "    \n",
    "    # - Pick the best candidate model    \n",
    "    best = best_candidate(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        bq_results = bq_results,\n",
    "        best_metric = best_metric,\n",
    "        candidates = candidate_models.outputs['candidates']\n",
    "    ).set_display_name('Pick The Best Candidate').set_caching_options(True)\n",
    "    \n",
    "    \n",
    "\n",
    "# - #Current model review path:\n",
    "#\n",
    "    # - Check for endpoint, create if needed\n",
    "    endpoint = get_endpoint(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series,\n",
    "        bq_dataset = bq_dataset \n",
    "    ).set_display_name('Get the Endpoint').set_caching_options(True)\n",
    "    \n",
    "    # - Get the deployed model with most traffic, if any\n",
    "    current_model = get_deployed_model(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = 'bqml_',\n",
    "        endpoint_resource_name = endpoint.outputs['endpoint_resource_name'] \n",
    "    ).set_display_name('Get The Deployed Model').set_caching_options(True)\n",
    "    #\n",
    "    # - Condition: if there is a deployed model\n",
    "    with dsl.Condition(\n",
    "        current_model.outputs['model'] != 'none',\n",
    "        name = 'compare_models'\n",
    "    ):\n",
    "    \n",
    "        # - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "        current_metrics = bqml_evaluate(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            bq_project = bq_project,\n",
    "            bq_dataset = bq_dataset,\n",
    "            bq_model = current_model.outputs['model'],\n",
    "            bq_test_table = bq_test_table,\n",
    "            bq_results = bq_results,\n",
    "            best_metric = best_metric\n",
    "        ).set_display_name('Gather Current Metrics').set_caching_options(True)\n",
    "    \n",
    "# - #Compare And update Path:\n",
    "#\n",
    "        # - Condition: if best > deployed\n",
    "        with dsl.Condition(\n",
    "            best.outputs['best_metric'] >= current_metrics.outputs['best_metric'],\n",
    "            name = 'replace_deployed_model'\n",
    "        ):\n",
    "            \n",
    "            # - deploy best on endpoint\n",
    "            deploy = deploy_candidate(\n",
    "                project = project,\n",
    "                region = region,\n",
    "                series = series,\n",
    "                endpoint_resource_name = endpoint.outputs['endpoint_resource_name'],\n",
    "                bq_model = best.outputs['best_candidate']\n",
    "            ).set_display_name('Deploy The Candidate Model').set_caching_options(True)\n",
    "            \n",
    "    ## - Condition: if there is not a deployed model\n",
    "    with dsl.Condition(\n",
    "        current_model.outputs['model'] == 'none',\n",
    "        name = 'deploy_model'\n",
    "    ):\n",
    "        \n",
    "        # - deploy best on endpoint\n",
    "        deploy = deploy_candidate(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            endpoint_resource_name = endpoint.outputs['endpoint_resource_name'],\n",
    "            bq_model = best.outputs['best_candidate']\n",
    "        ).set_display_name('Deploy The Candidate Model').set_caching_options(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e41d1-b009-4fbe-b940-0466534f89f5",
   "metadata": {},
   "source": [
    "### 4 - Compile And Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048df17-29fb-4174-916b-9892aae3ddf3",
   "metadata": {},
   "source": [
    "#### Collect Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4763b950-5e86-4f81-b5c4-3a74fc897d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:31.361426Z",
     "start_time": "2024-03-19T16:38:30.103455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f89411c4730>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_test_table = f\"{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_TEST\"\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE VIEW `{bq_test_table}` AS\n",
    "    SELECT * EXCEPT({','.join(VAR_OMIT.split())}, splits),\n",
    "    FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "    WHERE splits = 'TEST'\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61ac603f-c25b-45fd-b1db-2ca64eb2b956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:31.379848Z",
     "start_time": "2024-03-19T16:38:31.370099Z"
    }
   },
   "outputs": [],
   "source": [
    "parameter_values = {\n",
    "    \"project\" : PROJECT_ID,\n",
    "    \"region\" : REGION,\n",
    "    \"experiment\" : EXPERIMENT,\n",
    "    \"series\": SERIES,\n",
    "    \"bq_project\": BQ_PROJECT,\n",
    "    \"bq_dataset\": BQ_DATASET,\n",
    "    \"bq_test_table\": bq_test_table,\n",
    "    \"bq_results\": f\"{URI}/bq_results\",\n",
    "    \"best_metric\": 'accuracy' # accuracy, precision, recall, f1_score, log_loss, roc_auc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a8ddc-c632-4a63-ae37-2cd9b163251c",
   "metadata": {},
   "source": [
    "#### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd5f5fcf-08b4-4eeb-9f6c-8703a591691b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:31.439762Z",
     "start_time": "2024-03-19T16:38:31.385944Z"
    }
   },
   "outputs": [],
   "source": [
    "# from kfp.v2 import compiler\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func = endpoint_update_pipeline,\n",
    "    package_path = f\"{DIR}/{EXPERIMENT}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546e428-a295-4dff-b381-baa9c99a899e",
   "metadata": {},
   "source": [
    "#### Define Pipeline Job\n",
    "Using compiled pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c3acb880-8412-40b4-972b-068e30f0926a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:31.657247Z",
     "start_time": "2024-03-19T16:38:31.446107Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f\"{EXPERIMENT}_tournament\",\n",
    "    template_path = f\"{DIR}/{EXPERIMENT}.json\",\n",
    "    parameter_values = parameter_values,\n",
    "    pipeline_root = f\"{URI}/pipeline_root\",\n",
    "    enable_caching = True, # overrides all component/task settings\n",
    "    labels = {'experiment': EXPERIMENT, 'series': SERIES},\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446bff5d-ffca-4d05-8090-fa97f52e9c92",
   "metadata": {},
   "source": [
    "#### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "04b64989-573e-4452-bc9c-dfe68dc8bfed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:32.537703Z",
     "start_time": "2024-03-19T16:38:31.689797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/993073267534/locations/us-central1/pipelineJobs/series-bqml-endpoint-update-20240319113831\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/993073267534/locations/us-central1/pipelineJobs/series-bqml-endpoint-update-20240319113831')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/series-bqml-endpoint-update-20240319113831?project=993073267534\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc30d68-1c3b-493a-92c6-b35664d44c37",
   "metadata": {},
   "source": [
    "Using the following link to view the job in the GCP console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b17567cb-1038-46ca-8f52-e90cf2291f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:32.573208Z",
     "start_time": "2024-03-19T16:38:32.537388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/series-bqml-endpoint-update-20240319113831?project=993073267534\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd289e-dde8-4c6f-ad9d-c6946793158a",
   "metadata": {},
   "source": [
    "#### Wait On Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd7251a9-d2b6-4fa3-a442-b9f644b8675e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:44.940878Z",
     "start_time": "2024-03-19T16:38:32.550887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/993073267534/locations/us-central1/pipelineJobs/series-bqml-endpoint-update-20240319113831 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/993073267534/locations/us-central1/pipelineJobs/series-bqml-endpoint-update-20240319113831\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01108ed-4c60-44a3-b4d2-e8d24e5d0012",
   "metadata": {},
   "source": [
    "---\n",
    "## Work In Progress\n",
    "\n",
    "Use Vertex AI ML Metadata Artifact Types:\n",
    " - [Reference](https://cloud.google.com/vertex-ai/docs/pipelines/artifact-types)\n",
    " - [Consume or produce artifact in your component](https://cloud.google.com/vertex-ai/docs/pipelines/use-components#consume_or_produce_artifacts_in_your_component)\n",
    "\n",
    "```\n",
    "    # import prebuilt components\n",
    "    from google_cloud_pipeline_components.v1.bigquery import (\n",
    "        BigqueryEvaluateModelJobOp,\n",
    "        BigqueryMLConfusionMatrixJobOp,\n",
    "        BigqueryMLRocCurveJobOp\n",
    "    )\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from kfp.v2.components import importer_node\n",
    "\n",
    "...\n",
    "\n",
    "    with dsl.ParallelFor(candidate_models.outputs['candidates']) as candidate:\n",
    "        #candidate.set_display_name(str(candidate_models.outputs['candidates']))\n",
    "        \n",
    "        bqml_model = importer_node.importer(\n",
    "            artifact_uri = artifact_uri,\n",
    "            artifact_class = artifact_types.BQMLModel,\n",
    "            metadata = {\n",
    "                'projectId': \"statmike-mlops-349915\",\n",
    "                'datasetId': \"fraud\",\n",
    "                'modelId': \"03f_fraud_20220909135610\"\n",
    "            }\n",
    "        )\n",
    "        bq_eval = BigqueryEvaluateModelJobOp(\n",
    "            project = project,\n",
    "            location = region,\n",
    "            model = bqml_model.outputs['artifact'],\n",
    "            table_name = bq_test_table\n",
    "        )\n",
    "        bq_cm = BigqueryMLConfusionMatrixJobOp(\n",
    "            project = project,\n",
    "            location = region,\n",
    "            model = bqml_model.outputs['artifact'],\n",
    "            table_name = bq_test_table\n",
    "        )\n",
    "        bq_roc = BigqueryMLRocCurveJobOp(\n",
    "            project = project,\n",
    "            location = region,\n",
    "            model = bqml_model.outputs['artifact'],\n",
    "            table_name = bq_test_table\n",
    "        ) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24191d22-46dd-4145-bbb9-ec4a6784a40a",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T16:38:44.972696Z",
     "start_time": "2024-03-19T16:38:44.946047Z"
    }
   },
   "id": "af947c8630c9118d",
   "execution_count": 107
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
